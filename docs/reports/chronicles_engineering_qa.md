# Chronicles 엔지니어링 Q&A — 리뷰를 읽은 SW 엔지니어의 질문과 답변

> 이 문서는 [Chronicles 리뷰 기사](./chronicles_review_article.md)를 읽은 SW 엔지니어(🧑‍💻)가 제품 기획자/아키텍트(🏗️)에게 기술적 질문을 던지고 답변을 주고받는 형태의 중간 문서입니다. 제품의 기술적 실현 가능성과 아키텍처를 탐색하는 데 목적이 있습니다.

---

## Round 1: 장기 메모리 — "챕터 2 선택을 챕터 7에서 기억한다고?"

**🧑‍💻 엔지니어:** 리뷰에서 가장 인상적이었던 건 "챕터 2에서 Viktor를 보호한 선택을 챕터 7에서 Rain이 정확히 언급한다"는 부분이야. 근데 이거 기술적으로 어떻게 하는 거야? 현재 LLM의 컨텍스트 윈도우는 아무리 커도 128K~200K 토큰이잖아. 20챕터 분량의 전체 대화 히스토리를 다 넣으면 토큰이 수백만 개가 될 텐데.

**🏗️ 아키텍트:** 좋은 질문이야. 전체 대화를 컨텍스트에 다 넣는 건 당연히 불가능해. 이건 **계층적 메모리 시스템**으로 풀어야 해. 대략 3개 레이어를 생각하고 있어:

```
┌──────────────────────────────────────────────┐
│  Layer 1: Working Memory (현재 대화)          │
│  - 최근 20~30 턴의 raw 대화                   │
│  - 컨텍스트 윈도우의 ~40% 할당                 │
├──────────────────────────────────────────────┤
│  Layer 2: Episode Memory (챕터별 요약)         │
│  - 각 챕터 종료 시 LLM이 자동 요약 생성         │
│  - "이 챕터에서 일어난 핵심 사건 5개"           │
│  - "유저의 주요 선택과 그 결과"                 │
│  - JSON 구조화 → DB 저장                      │
├──────────────────────────────────────────────┤
│  Layer 3: Semantic Memory (관계/팩트 DB)       │
│  - "Rain은 유저를 '비에 젖은 손님'이라 부른다"  │
│  - "유저는 챕터 2에서 Viktor에게 거짓말했다"     │
│  - "Rain의 신뢰도: 55%, 경계심: 15%"           │
│  - 구조화된 key-value 또는 그래프 DB            │
└──────────────────────────────────────────────┘
```

매 턴마다 LLM에 보내는 프롬프트는 이렇게 구성돼:

```
[시스템 프롬프트] + [Layer 3에서 현재 관련 팩트 검색] 
+ [Layer 2에서 관련 챕터 요약 검색] + [Layer 1 최근 대화]
```

Layer 3에서 "관련 팩트 검색"은 RAG (Retrieval-Augmented Generation) 방식이야. 현재 대화 맥락에서 관련 키워드/임베딩을 뽑아서 시맨틱 서치하는 거지.

**🧑‍💻 엔지니어:** 그러면 챕터가 끝날 때마다 요약 파이프라인이 돌아야 하겠네? 그 요약의 품질이 곧 기억의 품질이니까 — 요약이 잘못되면 나중에 모순이 생길 수도 있겠는데?

**🏗️ 아키텍트:** 맞아, 이게 핵심 리스크야. 그래서 **이중 검증 요약(Dual-pass Summarization)**을 쓸 생각이야:

1. **1차 요약**: 챕터 종료 시 LLM이 "이 챕터의 핵심 사건, 유저 선택, 관계 변화"를 구조화된 JSON으로 추출
2. **2차 검증**: 별도 LLM 호출로 "1차 요약이 실제 대화와 일관성이 있는지" 크로스체크. 모순이 발견되면 재생성

이걸 유저 체감 없이 하려면 챕터 엔딩 컷씬(예: "To be continued..." 화면)을 보여주는 5~10초 동안 백그라운드에서 처리하면 돼. 자연스러운 UX 틈새를 활용하는 거지.

**🧑‍💻 엔지니어:** 아 — 챕터 구분이 있으니까 요약 시점이 자연스럽게 정해지는 거구나. 기존 AI 채팅은 끊김이 없는 무한 대화라서 "언제 요약할 건데?"라는 문제가 있는데, 챕터 구조가 아키텍처적으로도 이점이 있네.

**🏗️ 아키텍트:** 정확해. **챕터 구조는 UX 선택인 동시에 아키텍처 선택**이야. 기존 AI 채팅의 "무한 대화"는 메모리 관리의 악몽이거든. Chronicles에서 챕터는 세이브 포인트이자, 메모리 컴팩션 포인트이자, 품질 검증 포인트인 셈이야.

---

## Round 2: 관계도 게이지 — "AI가 어떻게 경계심, 호감, 신뢰를 구분하지?"

**🧑‍💻 엔지니어:** 관계도에 "경계심 90%, 호감 10%, 신뢰 0%"처럼 수치가 나오잖아. 이 수치를 누가 갱신하는 거야? LLM이 직접 계산? 아니면 별도 로직?

**🏗️ 아키텍트:** 이건 **LLM + 규칙 엔진 하이브리드**야. 순서는 이래:

```
유저 입력
    │
    ▼
┌─────────────────────────────────┐
│ ① LLM: 감정 분석 (Emotion Judge) │
│   "이 발화가 Rain에게 어떤        │
│    감정적 영향을 미치는가?"        │
│                                 │
│   Output (JSON):                │
│   {                             │
│     "perceived_intent": "직접적  │
│       개인 질문",                │
│     "emotional_impact": {        │
│       "경계심": +8,              │
│       "호감도": -2,              │
│       "신뢰도": 0                │
│     },                          │
│     "reasoning": "Rain은 초면에  │
│       개인 정보를 묻는 것을       │
│       침범으로 느낀다"            │
│   }                             │
└───────────────┬─────────────────┘
                │
                ▼
┌─────────────────────────────────┐
│ ② Rule Engine: 수치 반영         │
│   - 경계심: min(100, 90+8) = 98  │
│   - 하지만 캡 규칙: 한 턴에       │
│     최대 ±15 제한 → 98 OK       │
│   - 호감도: max(0, 10-2) = 8     │
│   - 이벤트 트리거 체크:           │
│     "경계심 > 95 → 대화 단절      │
│      이벤트 발동?"  → NO (98<95?) │
│     → 오타 수정: > 95이니 YES!   │
│     → "Rain이 자리를 떠난다"      │
└───────────────┬─────────────────┘
                │
                ▼
┌─────────────────────────────────┐
│ ③ LLM: 응답 생성                 │
│   System Prompt에 현재 관계 수치  │
│   + 감정 상태 주입               │
│   "너는 Rain이다. 현재 경계심 98, │
│    호감 8. 매우 경계 중.          │
│    자리를 뜨려는 충동이 있다."     │
│                                 │
│   → Rain의 대사 생성             │
└─────────────────────────────────┘
```

핵심은 LLM이 수치를 "직접 계산"하지 않는다는 거야. LLM은 **감정 판단**만 하고, 실제 수치 연산은 **결정론적 규칙 엔진**이 해. 왜냐하면 LLM한테 "지금 경계심이 몇이야?"를 계산하라고 하면 턴마다 흔들리거든. 55였다가 갑자기 30이 되고, 다음 턴에 70이 되고... 이렇게 되면 게이지의 신뢰성이 무너져.

**🧑‍💻 엔지니어:** 아, 그래서 수치 연산은 규칙 기반이고, LLM은 "이 발화가 상대에게 플러스인지 마이너스인지"를 판단하는 감정 분석기 역할만 하는 거구나. 근데 그러면 **LLM 호출이 한 턴에 최소 2번** 필요하잖아? (감정 분석 1번 + 응답 생성 1번) 비용이 2배?

**🏗️ 아키텍트:** 맞아, 이건 트레이드오프야. 몇 가지 최적화 방안이 있어:

| 방안 | 설명 | 절감 |
|------|------|------|
| **배치 호출** | 감정 분석과 응답 생성을 하나의 프롬프트에 합침. "먼저 JSON으로 감정 영향을 출력하고, 그 다음 캐릭터 대사를 출력해" | ~40% |
| **경량 모델 분리** | 감정 분석은 작은 모델 (GPT-4o-mini급), 응답 생성은 큰 모델 사용 | ~30% |
| **캐싱** | 비슷한 유형의 발화("이름 묻기", "칭찬하기" 등)를 패턴 분류하고 자주 나오는 패턴은 룩업 테이블로 처리 | ~20% |

현실적으로는 **배치 호출을 기본**으로 하고, 고부하 시나리오에서만 경량 모델 분리를 적용할 것 같아.

**🧑‍💻 엔지니어:** 한 가지 더 — 관계 수치가 캐릭터 행동에 반영되는 방식이 궁금해. 호감도 80인 Rain과 호감도 20인 Rain은 **구체적으로 뭐가 다르게** 생성되는 거야?

**🏗️ 아키텍트:** 이건 시스템 프롬프트에 주입되는 **캐릭터 상태 디렉티브**로 제어해. 예시를 보여줄게:

```markdown
## 호감도 20 이하일 때 Rain의 행동 디렉티브:
- 대화를 짧게 끊는다. 3문장 이상 말하지 않는다.
- 눈을 잘 마주치지 않는다 (묘사에 반영).
- 개인적인 이야기를 절대 먼저 꺼내지 않는다.
- 유저가 신체 접촉을 시도하면 즉시 거부한다.
- 바를 떠날 이유를 자주 언급한다 ("이만 가봐야겠어요").

## 호감도 60~80일 때 Rain의 행동 디렉티브:
- 대화가 길어져도 괜찮다. 자연스럽게 화제를 확장한다.
- 유저의 농담에 웃는다 (묘사에 반영).
- 과거에 대한 힌트를 살짝 흘린다 (단, 핵심은 아직 숨긴다).
- 가끔 유저의 의견을 먼저 물어본다.
- 실수로 유저를 본명 대신 별명으로 부를 수 있다.

## 호감도 80 이상일 때 Rain의 행동 디렉티브:
- 감정적으로 솔직해진다. 불안이나 두려움도 표현한다.
- 먼저 바를 찾아온다 (유저가 부르지 않아도).
- 과거의 핵심 사건을 공유할 수 있다.
- 신체적 친밀감에 거부감이 줄어든다 (단, 신뢰도도 50+ 필요).
- "당신이 없었으면..."류의 의존적 발화가 가능해진다.
```

이 디렉티브가 **동적으로 선택**되어 시스템 프롬프트에 삽입되는 거야. LLM은 이 디렉티브를 따르면서도 자연스러운 대화를 생성하는 역할을 해. 핵심은 디렉티브가 "대사"를 지정하는 게 아니라 "행동 경향"을 지정한다는 거야. 그래서 매번 다른 대사가 나와도 일관된 캐릭터성이 유지돼.

---

## Round 3: 분기와 멀티엔딩 — "진짜 47번 분기를 다 설계한 거야?"

**🧑‍💻 엔지니어:** 리뷰에 "47번의 분기 선택"이라고 나와 있는데, 이걸 다 수동으로 설계하면 시나리오 작가가 죽을 텐데. 모든 분기 조합의 결과를 다 작성할 수는 없잖아. 2^47이면 경우의 수가...

**🏗️ 아키텍트:** ㅋㅋ 물론 2^47개 루트를 다 설계하지 않아. 이건 **레일 + 자유도 하이브리드** 구조야. 내부적으로 우리가 부르는 이름은 "가드레일 내러티브(Guardrailed Narrative)"인데:

```
시나리오 작가가 설계하는 것:
  ✅ 챕터별 핵심 이벤트 (필수 발생) — "플롯 앵커"
  ✅ 주요 분기 포인트 5~7개 (대분기)
  ✅ 엔딩 3~5개
  ✅ 각 캐릭터의 성격/동기/비밀 설정 문서

AI가 생성하는 것:
  🤖 플롯 앵커 사이의 대화와 소소한 이벤트
  🤖 유저의 자유 입력에 대한 반응
  🤖 관계 수치에 따른 캐릭터 태도 변화
  🤖 소분기 (대분기의 바리에이션)
```

다이어그램으로 보면 이래:

```
챕터 1          챕터 2          챕터 3
[앵커: 만남] → [앵커: Viktor 등장] → [앵커: 정체 공개]
     │              │                    │
     │   ┌──── 대분기 ────┐              │
     │   │               │              │
     │  Viktor편       Rain편            │
     │   │               │              │
     │   ▼               ▼              │
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  ~  이 구간은 AI가 자유 생성하는 영역   ~
  ~  관계 수치 + 디렉티브 기반          ~
  ~  유저마다 완전히 다른 대화 발생      ~
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                                         │
                              ┌────── 대분기 ─────┐
                              │                  │
                          신뢰도 50+          신뢰도 50-
                          Rain 공개           Rain 도주
```

**핵심 인사이트: "47번의 분기"는 작가가 만든 대분기 5~7개 + AI가 즉석 생성한 소분기 40여 개의 합산이야.** 유저는 이 차이를 모르고, 모든 분기가 "설계된 것"처럼 느껴.

**🧑‍💻 엔지니어:** 아 — 그래서 "플롯 앵커"는 반드시 발생하되, 그 사이를 AI가 채우는 거구나. 그러면 플롯 앵커에 도달하는 **조건 관리**는 어떻게 해? 예를 들어 "Rain이 챕터 3에서 정체를 공개한다"가 앵커라면, 유저가 Rain과 대화를 전혀 안 해도 강제로 발동되는 건가?

**🏗️ 아키텍트:** 그건 **트리거 조건 + 폴백 메커니즘**으로 처리해:

```python
# 플롯 앵커 정의 예시
plot_anchor = {
    "id": "ch3_identity_reveal",
    "chapter": 3,
    "description": "Rain이 자신의 직업을 공개한다",
    
    # 이상적 트리거 (유저 행동으로 자연스럽게 도달)
    "ideal_trigger": {
        "condition": "rain.trust >= 25 AND rain.suspicion <= 60",
        "narrative_hook": "Rain이 먼저 고백을 결심한다"
    },
    
    # 폴백 트리거 (유저가 관련 상호작용을 안 한 경우)
    "fallback_trigger": {
        "condition": "chapter_progress >= 80%",
        "narrative_hook": "외부 사건(Viktor의 습격)이 발생하여 Rain의 정체가 강제로 드러난다"
    },
    
    # 최종 폴백 (어떤 경우에도 챕터 4 진입 전 반드시 발동)
    "hard_deadline": "chapter_end",
    "hard_fallback": "Rain이 뉴스 보도를 통해 간접적으로 정체가 밝혀진다"
}
```

이렇게 하면 유저의 플레이 스타일에 따라 **같은 앵커가 다른 방식으로 발동**돼. 적극적으로 Rain과 관계를 쌓은 유저는 "Rain이 마음을 열어서 고백"이고, 소극적 유저는 "사건이 터져서 어쩔 수 없이 밝혀지는" 전개가 되는 거야. 양쪽 다 스토리적으로 자연스럽지만, 감정적 맛이 완전히 달라.

**🧑‍💻 엔지니어:** 우와, 이러면 시나리오 작가가 앵커 하나당 **최소 2~3개의 도달 경로**를 써야 하네. 작업량이 꽤 될 텐데?

**🏗️ 아키텍트:** 맞아. 그래서 런칭 시 시나리오가 3개뿐인 거야. 하나의 시나리오(20챕터)를 만드는 데 필요한 리소스가:

| 항목 | 분량 |
|------|------|
| 플롯 앵커 | 챕터당 1~2개 × 20챕터 = 25~40개 |
| 앵커당 도달 경로 | 2~3개 = 총 60~120개의 내러티브 훅 |
| 대분기 | 5~7개 (각각 후속 챕터 흐름에 영향) |
| 캐릭터 설정 문서 | 메인 캐릭터 1 + NPC 3~5 = 총 4~6개 |
| 엔딩 | 3~5개 |
| QA/테스트 플레이 | 최소 5회 풀 플레이스루 |

전체적으로 **시나리오 1개당 2~3개월의 제작 기간**이 필요할 것 같아. 그래서 초기 이후에는 **UGC (유저 생성 시나리오) 도구**를 열어서 커뮤니티가 시나리오를 만들 수 있게 하는 게 로드맵에 있어. 작가가 플롯 앵커와 캐릭터만 설정하면, AI가 나머지를 채우는 "시나리오 에디터"를 제공하는 거지.

---

## Round 4: 성인 콘텐츠 생성 — "안전장치를 어떻게 설계하는 거야?"

**🧑‍💻 엔지니어:** 성인 콘텐츠 생성 파이프라인이 제일 까다로울 것 같아. LLM 프로바이더(OpenAI 등)는 NSFW 출력을 기본 차단하잖아. 어떤 모델을 쓰는 거야?

**🏗️ 아키텍트:** 이건 아키텍처에서 제일 민감한 부분이야. 현실적으로 몇 가지 옵션이 있어:

```
옵션 A: 자체 파인튜닝 모델
  - 오픈소스 베이스 (LLaMA 3, Mistral 등) + NSFW 데이터로 파인튜닝
  - 장점: 완전한 제어, 검열 없음
  - 단점: 인프라 비용 높음, 모델 품질 관리 필요

옵션 B: NSFW 허용 API 사용
  - 일부 프로바이더 (예: Together AI, DeepInfra 등)가
    uncensored 모델 API를 제공
  - 장점: 인프라 부담 적음
  - 단점: 서드파티 의존, 정책 변경 리스크

옵션 C: 하이브리드 (추천)
  - 일반 대화/스토리: 대형 모델 API (GPT-4o, Claude 등)
  - 성인 장면: 자체 호스팅 파인튜닝 모델
  - 장점: 품질 + 자유도 둘 다 확보
  - 단점: 두 모델 간 톤 일관성 유지 필요
```

우리가 가려는 방향은 **옵션 C**야. 일반 대화는 대형 모델의 높은 품질을 활용하고, 성인 장면 진입 시 자체 모델로 전환해. 전환이 부자연스럽지 않으려면, 전환 지점에서 **캐릭터 컨텍스트 브리지(context handoff)**를 잘 넘겨야 해.

**🧑‍💻 엔지니어:** 전환 시점은 어떻게 감지해? 유저가 갑자기 성적인 메시지를 보내면 그때 전환하는 거야?

**🏗️ 아키텍트:** 아니, **유저가 갑자기 보내는 건 별도 처리**하고, 정상적인 시나리오 흐름에서는 이렇게 작동해:

```
시나리오 진행 중 → 친밀 장면 진입 조건 충족?
   │
   ├── NO → 일반 모델 계속 사용
   │
   └── YES  (관계 수치 + 플롯 앵커 조건 모두 충족)
        │
        ├── 시스템: "분위기가 달라지고 있습니다" UI 표시
        ├── 유저 톤 설정 확인 (소프트/미디엄/볼드/익스플리싯)
        ├── 연령 인증 재확인 (익스플리싯의 경우)
        │
        └── 모델 전환: 자체 파인튜닝 모델로 스위칭
             │
             Context Handoff:
             - 현재 관계 수치
             - 최근 5턴 대화
             - 캐릭터 감정 상태
             - 톤 레벨 디렉티브
             - 장면의 내러티브 컨텍스트
               ("Rain은 Viktor 사건 이후 처음으로
                감정적으로 열려 있다")
```

유저가 갑자기 성적 메시지를 보내는 경우에는 **관계 수치 기반 게이트**가 있어:

```
유저가 성적 발화 감지 (분류 모델)
   │
   ├── 관계 수치 충분 (호감 70+, 신뢰 50+)
   │   → 자연스러운 장면 전환
   │
   ├── 관계 수치 부족
   │   → 캐릭터가 거절/회피 (in-character)
   │   → "Rain이 당신의 손을 밀어내며:
   │      '...아직은 아니야. 당신을 더 알고 싶어.'"
   │   → 경계심 +10
   │
   └── 관계 수치 매우 낮음 (호감 30-)
       → 강한 거절 + 관계 페널티
       → "Rain이 자리에서 일어선다. 
          더 이상 이 대화를 이어갈 생각이 없어 보인다."
```

이렇게 하면 **검열이 아닌 "캐릭터의 의지"로 제한**이 느껴지기 때문에, 유저 불만이 기존 앱의 "필터에 막혔다" 느낌과 완전히 달라. "Rain이 아직 준비가 안 됐구나. 더 노력해야겠다"가 되는 거야.

**🧑‍💻 엔지니어:** 오... 이건 정말 영리한 설계인데? 기술적 제약을 **게임 메카닉으로 포장**한 거잖아. 유저 입장에서는 "필터 = 나쁜 것"이 되는데, "캐릭터가 거절 = 게임의 일부"가 되는 거고.

**🏗️ 아키텍트:** 그게 핵심이야. **검열을 게임 디자인으로 변환하는 것.** 기존 AI 채팅의 가장 큰 실패는 필터링을 "차단"으로 구현한 거거든. "이 대화는 정책에 위반됩니다" 같은 메타 메시지가 뜨면 몰입이 완전히 깨지잖아. Chronicles에서는 그런 메타 메시지가 절대 뜨면 안 돼. 모든 제한은 **인캐릭터(in-character)로 자연스럽게** 표현되어야 해.

---

## Round 5: 인프라와 비용 — "유저당 비용이 얼마나 나올까?"

**🧑‍💻 엔지니어:** 이 구조면 한 턴에 최소 LLM 호출이 1~2회인데, 유저가 하루에 30분씩 플레이하면... 대략 유저당 월 비용이 얼마나 나올 것 같아?

**🏗️ 아키텍트:** 대략 추산해 볼게:

```
가정:
  - 세션당 30분, 하루 1세션
  - 턴당 평균 입출력: 500 토큰 (입력 300 + 출력 200)
  - 시스템 프롬프트 + 컨텍스트: 2,000 토큰 (매 턴)
  - 턴 간격: 약 1분
  - → 세션당 약 30턴

=== 일반 대화 (대형 모델 API, 예: GPT-4o) ===
  턴당 토큰: 2,500 (컨텍스트 포함)
  30턴 × 2,500 = 75,000 토큰/세션
  30일 = 2,250,000 토큰/월
  GPT-4o 가격 기준 ($2.50/1M input, $10/1M output):
  → 입력: 1,800K × $2.50/1M = $4.50
  → 출력: 450K × $10/1M = $4.50
  → 소계: ~$9.00/월/유저

=== 성인 장면 (자체 호스팅 모델) ===
  전체 대화의 약 15%로 가정
  GPU 비용 (A100 기준): ~$1.50/월/유저 (배치 최적화 후)

=== 메모리 시스템 (요약/검색) ===
  챕터 요약 + RAG 검색: ~$0.50/월/유저

=== 총합 ===
  ~$11.00/월/유저
```

**🧑‍💻 엔지니어:** 구독료가 $9.99인데 유저당 비용이 $11이면... **적자잖아?**

**🏗️ 아키텍트:** 맞아. 이걸 해결하는 방법이 몇 가지 있어:

| 전략 | 절감 효과 | 설명 |
|------|----------|------|
| **모델 경량화** | -40% | GPT-4o 대신 4o-mini를 기본으로, 중요 장면에서만 4o 사용 |
| **응답 캐싱** | -15% | 유사 시나리오 진행의 공통 응답 패턴 캐싱 |
| **턴 길이 최적화** | -10% | AI가 너무 긴 응답을 생성하지 않도록 디렉티브 |
| **구독 티어 분화** | - | $9.99 (기본) / $19.99 (풀 품질) |

모델 경량화만 적용해도 비용이 **~$6.60/월/유저**로 떨어져서 마진이 생겨. 그리고 현실적으로 **모든 유저가 매일 30분씩 플레이하진 않아**. 평균 DAU/MAU 비율이 30% 정도라고 보면 실제 유저당 평균 비용은 $4~5 수준이야.

**🧑‍💻 엔지니어:** 아, 맞다. 비용은 "활성 유저 기준"이고 구독은 "전체 구독자 기준"이니까 자연스럽게 마진이 나오는 구조구나. 게임으로 치면 "과금은 하지만 매일 접속 안 하는 유저"가 수익을 만드는 거랑 같은 원리.

---

## Round 6: 스케일링 — "유저 10만 명이면 인프라가 어떻게 되지?"

**🧑‍💻 엔지니어:** 마지막으로 스케일 이야기. 동시접속 유저가 1만 명이라고 치면, LLM 호출이 분당 1만 건. 이건 어떤 인프라가 필요해?

**🏗️ 아키텍트:** 이건 단계적으로 접근해야 해:

```
Phase 1: 런칭 초기 (유저 1만 명, DAU 3천)
├─ 피크 동시접속: ~500명
├─ 분당 LLM 호출: ~500건
├─ 인프라: 외부 API (GPT-4o) + 자체 GPU 2~4대 (A100)
├─ 월 인프라 비용: ~$15,000
└─ 손익분기: 유료 구독자 ~2,000명

Phase 2: 성장기 (유저 10만 명, DAU 3만)
├─ 피크 동시접속: ~5,000명
├─ 분당 LLM 호출: ~5,000건
├─ 인프라: API 레이트리밋 대응 필요
│   → 멀티 프로바이더 (OpenAI + Anthropic + 자체)
│   → 로드밸런서 + 큐 시스템
├─ 자체 GPU 클러스터: 8~16대
├─ 월 인프라 비용: ~$80,000
└─ 손익분기: 유료 구독자 ~12,000명

Phase 3: 스케일 (유저 100만 명)
├─ 자체 모델 비중을 최대한 올려 API 의존 줄임
├─ 추론 최적화 (vLLM, TensorRT-LLM 등)
├─ 리전별 GPU 분산
└─ 월 인프라 비용: ~$400,000+
```

**🧑‍💻 엔지니어:** Phase 1이 현실적이네. GPU 4대 + API로 시작할 수 있으면 초기 투자가 생각보다 크지 않아. DAU 3천이면 피크 500명이니까 API 레이트리밋에도 여유가 있고.

**🏗️ 아키텍트:** 맞아. 그리고 Phase 1에서 중요한 건 **데이터를 모으는 것**이야. 유저들의 실제 플레이 패턴, 인기 있는 분기, 평균 세션 길이... 이런 데이터가 모이면 Phase 2에서의 모델 파인튜닝과 캐싱 전략을 데이터 기반으로 최적화할 수 있어. 그래서 Phase 1은 "돈 버는 단계"가 아니라 "학습하는 단계"야.

**🧑‍💻 엔지니어:** 정리하면, 기술적으로 불가능한 건 없고 — 핵심 챌린지는:

1. **메모리 품질**: 요약의 정확성이 곧 사용자 경험
2. **비용 최적화**: 경량 모델 + 캐싱으로 마진 확보
3. **톤 일관성**: 일반 모델 ↔ 성인 모델 전환 시 캐릭터 단절 방지
4. **시나리오 제작 파이프라인**: 앵커 기반 시스템으로 작가 생산성 확보

**🏗️ 아키텍트:** 완벽한 요약이야. 그리고 한 가지 더 — **가장 과소평가되는 챌린지**가 있어:

5. **관계 게이지의 밸런싱**: 게이지가 너무 쉽게 오르면 기존 AI 채팅이랑 다를 게 없고, 너무 어려우면 유저가 지쳐서 이탈해. 이건 게임 밸런싱과 똑같은 문제이고, **실제 유저 데이터 없이는 절대 정답을 찾을 수 없어.** 그래서 Phase 1에서의 A/B 테스트가 정말 중요해.

---

## 요약: 기술 스택 오버뷰

```
┌─────────────────────────────────────────────────────┐
│                    클라이언트                         │
│   React Native (iOS/Android) + Web (Next.js)        │
│   - 챕터 UI, 관계도 게이지, 대시보드                   │
│   - 시네마틱 장면 뷰어                               │
└────────────────────────┬────────────────────────────┘
                         │
                    API Gateway
                         │
┌────────────────────────┼────────────────────────────┐
│                    백엔드 서버                        │
│                                                     │
│  ┌──────────┐  ┌──────────┐  ┌───────────────────┐  │
│  │ 대화 엔진 │  │ 관계도    │  │ 시나리오 엔진     │  │
│  │ (LLM     │  │ 규칙 엔진 │  │ (앵커 관리,       │  │
│  │  오케스트 │  │ (수치 연산│  │  분기 추적,       │  │
│  │  레이터) │  │  이벤트   │  │  트리거 평가)     │  │
│  │          │  │  트리거)  │  │                   │  │
│  └────┬─────┘  └────┬─────┘  └────────┬──────────┘  │
│       │             │                 │              │
│  ┌────┴─────────────┴─────────────────┴──────────┐  │
│  │              메모리 시스템                       │  │
│  │  Working Memory │ Episode Memory │ Semantic DB  │  │
│  │  (Redis)        │ (PostgreSQL)   │ (pgvector)   │  │
│  └───────────────────────────────────────────────┘  │
└────────────────────────┬────────────────────────────┘
                         │
          ┌──────────────┼──────────────┐
          │              │              │
   ┌──────┴──────┐ ┌────┴─────┐ ┌─────┴──────┐
   │ 외부 LLM API│ │자체 GPU  │ │ 이미지 생성 │
   │ (일반 대화) │ │(성인 장면)│ │ (장면 삽화) │
   │ GPT-4o-mini │ │ LLaMA FT │ │ SDXL / Flux│
   └─────────────┘ └──────────┘ └────────────┘
```

---

*이 문서는 리뷰 기사에 기반한 가상의 기술 Q&A이며, 실제 구현 시 변경될 수 있습니다. 제품 이해도를 높이기 위한 중간 탐색 문서로 활용합니다.*
